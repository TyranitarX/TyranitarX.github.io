<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>卷积神经网络 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="一、卷积对于普通神经网络来说，每层神经元的输入，即是上一层神经元的输出。假设一张图片为1000×1000,就会出现1000×1000个参数若下一层神经元个数为10^6个全连接参数为1000×1000×10^6 &#x3D;10^12个这个参数量是非常大的，这样处理不仅会增加训练时计算机的负担，由于参数量过大，其模型表达能力也非常强。虽然在训练集上效果极佳，但是在训练集上测试效果较差。即出现过拟合问题。因此，">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络">
<meta property="og:url" content="http://yoursite.com/2019/07/06/cnn/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="一、卷积对于普通神经网络来说，每层神经元的输入，即是上一层神经元的输出。假设一张图片为1000×1000,就会出现1000×1000个参数若下一层神经元个数为10^6个全连接参数为1000×1000×10^6 &#x3D;10^12个这个参数量是非常大的，这样处理不仅会增加训练时计算机的负担，由于参数量过大，其模型表达能力也非常强。虽然在训练集上效果极佳，但是在训练集上测试效果较差。即出现过拟合问题。因此，">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-07-06T00:44:55.000Z">
<meta property="article:modified_time" content="2019-07-06T02:18:46.010Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-cnn" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/06/cnn/" class="article-date">
  <time datetime="2019-07-06T00:44:55.000Z" itemprop="datePublished">2019-07-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      卷积神经网络
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="一、卷积"><a href="#一、卷积" class="headerlink" title="一、卷积"></a>一、卷积</h2><p>对于普通神经网络来说，每层神经元的输入，即是上一层神经元的输出。<br>假设一张图片为1000×1000,就会出现1000×1000个参数<br>若下一层神经元个数为10^6个<br>全连接参数为1000×1000×10^6 =10^12个<br>这个参数量是非常大的，这样处理不仅会增加训练时计算机的负担，<br>由于参数量过大，其模型表达能力也非常强。虽然在训练集上效果极佳，但是在训练集上测试效果较差。<br>即出现过拟合问题。<br>因此，我们使用了卷积操作来解决这个问题。</p>
<h3 id="输入图像："><a href="#输入图像：" class="headerlink" title="输入图像："></a>输入图像：</h3><table>
<thead>
<tr>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
</tr>
</thead>
<tbody><tr>
<td align="center">6</td>
<td align="center">7</td>
<td align="center">8</td>
<td align="center">9</td>
<td align="center">10</td>
</tr>
<tr>
<td align="center">11</td>
<td align="center">12</td>
<td align="center">13</td>
<td align="center">14</td>
<td align="center">15</td>
</tr>
<tr>
<td align="center">16</td>
<td align="center">17</td>
<td align="center">18</td>
<td align="center">19</td>
<td align="center">20</td>
</tr>
<tr>
<td align="center">21</td>
<td align="center">22</td>
<td align="center">23</td>
<td align="center">24</td>
<td align="center">25</td>
</tr>
<tr>
<td align="center">### 卷积核：</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">:————:</td>
<td align="center">:————:</td>
<td align="center">:————:</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">### 输出：</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">35</td>
<td align="center">？</td>
<td align="center">？</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">:————:</td>
<td align="center">:————:</td>
<td align="center">:————:</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">？</td>
<td align="center">？</td>
<td align="center">？</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">？</td>
<td align="center">？</td>
<td align="center">？</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">卷积核在输入图像上滑动并进行点积运算，得到卷积后的图像。</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">其滑动长度叫做步长</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><div style=color:red;font-size:20px>输出size=输入size-卷积核size+1</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<p>显然，每次卷积会使图像size变小，在CNN中可能有不只一层卷积层。如果图像本身较小，很有可能经过多次卷积操作使图像变为1×1的像素点。这样对描述图片的特征是很不直观的。</p>
<p>因此我们可以使用一种padding操作，在输入图像周围加入值为0的像素点。</p>
<table>
<thead>
<tr>
<th align="center">0</th>
<th align="center">0</th>
<th align="center">0</th>
<th align="center">0</th>
<th align="center">0</th>
<th align="center">0</th>
<th align="center">0</th>
</tr>
</thead>
<tbody><tr>
<td align="center">0</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
</tbody></table>
<p>当然加入几层padding和卷积核的大小有关，进行合适的处理即能够使输入和输出的size相同。</p>
<p>对于多通道图片，我们将卷积核也变为多通道即可。不通通道图片上卷积参数并不共享，多个通道卷积之后的相应位置像素相加作为最后的输出（activation maps）。</p>
<p>同样，通过多个卷积核，能够产生多通道输出，提取出不同的特征。</p>
<h2 id="二、激活函数"><a href="#二、激活函数" class="headerlink" title="二、激活函数"></a>二、激活函数</h2><p>Sigmoid=1/1+e^-x<br>tanh=tanh（x）<br>ReLU=max(0,x)<br>Leaky ReLU=max(0.1x,x)<br>Maxout<br>ELU 等</p>
<p>对于卷积神经网络来说，常用的激活函数为ReLU函数。</p>
<table>
<thead>
<tr>
<th align="center">5</th>
<th align="center">6</th>
<th align="center">-2</th>
</tr>
</thead>
<tbody><tr>
<td align="center">-10</td>
<td align="center">0</td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">9</td>
<td align="center">-1</td>
<td align="center">7</td>
</tr>
</tbody></table>
<p>ReLU激活后-&gt;</p>
<table>
<thead>
<tr>
<th align="center">5</th>
<th align="center">6</th>
<th align="center">0</th>
</tr>
</thead>
<tbody><tr>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">9</td>
<td align="center">0</td>
<td align="center">7</td>
</tr>
</tbody></table>
<h3 id="卷积-Summary"><a href="#卷积-Summary" class="headerlink" title="卷积-Summary"></a>卷积-Summary</h3><ul>
<li>P = 边距（padding）</li>
<li>S = 步长（stride）</li>
<li>输出Size =（n-p）/s + 1</li>
<li>参数数目 = kw × kh × Ci × Co<ul>
<li>Ci:输出通道数</li>
<li>Co:输出通道数</li>
<li>Kw,Kh:卷积核长宽</li>
</ul>
</li>
</ul>
<h2 id="三、池化"><a href="#三、池化" class="headerlink" title="三、池化"></a>三、池化</h2><ul>
<li><h5 id="常使用不重叠、不补零"><a href="#常使用不重叠、不补零" class="headerlink" title="常使用不重叠、不补零"></a>常使用不重叠、不补零</h5></li>
<li><h5 id="没有用于求导的参数"><a href="#没有用于求导的参数" class="headerlink" title="没有用于求导的参数"></a>没有用于求导的参数</h5></li>
<li><h5 id="池化层的参数为步长和池化核的大小"><a href="#池化层的参数为步长和池化核的大小" class="headerlink" title="池化层的参数为步长和池化核的大小"></a>池化层的参数为步长和池化核的大小</h5></li>
<li><h5 id="池化用于减少图像尺寸，从而减少计算量"><a href="#池化用于减少图像尺寸，从而减少计算量" class="headerlink" title="池化用于减少图像尺寸，从而减少计算量"></a>池化用于减少图像尺寸，从而减少计算量</h5></li>
<li><h5 id="一定程度解决平移鲁棒"><a href="#一定程度解决平移鲁棒" class="headerlink" title="一定程度解决平移鲁棒"></a>一定程度解决平移鲁棒</h5></li>
<li><h5 id="一定程度上损失空间位置精度"><a href="#一定程度上损失空间位置精度" class="headerlink" title="一定程度上损失空间位置精度"></a>一定程度上损失空间位置精度</h5></li>
</ul>
<h3 id="输入图像：-1"><a href="#输入图像：-1" class="headerlink" title="输入图像："></a>输入图像：</h3><table>
<thead>
<tr>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
</tr>
</thead>
<tbody><tr>
<td align="center">6</td>
<td align="center">7</td>
<td align="center">8</td>
<td align="center">9</td>
<td align="center">10</td>
</tr>
<tr>
<td align="center">11</td>
<td align="center">12</td>
<td align="center">13</td>
<td align="center">14</td>
<td align="center">15</td>
</tr>
<tr>
<td align="center">16</td>
<td align="center">17</td>
<td align="center">18</td>
<td align="center">19</td>
<td align="center">20</td>
</tr>
<tr>
<td align="center">21</td>
<td align="center">22</td>
<td align="center">23</td>
<td align="center">24</td>
<td align="center">25</td>
</tr>
<tr>
<td align="center">Max-pool操作</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Stride = 2</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Kernel_size = 2 * 2</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">### 输出：</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">7</td>
<td align="center">9</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">:————:</td>
<td align="center">:————:</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">17</td>
<td align="center">19</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<p>Avg-pool操作<br>Stride = 2<br>Kernel_size = 2 * 2</p>
<h3 id="输出："><a href="#输出：" class="headerlink" title="输出："></a>输出：</h3><table>
<thead>
<tr>
<th align="center">4</th>
<th align="center">6</th>
</tr>
</thead>
<tbody><tr>
<td align="center">14</td>
<td align="center">16</td>
</tr>
</tbody></table>
<h2 id="四、全连接层"><a href="#四、全连接层" class="headerlink" title="四、全连接层"></a>四、全连接层</h2><h4 id="将上一层的输出展开并连接到每一个神经元上"><a href="#将上一层的输出展开并连接到每一个神经元上" class="headerlink" title="将上一层的输出展开并连接到每一个神经元上"></a>将上一层的输出展开并连接到每一个神经元上</h4><h4 id="即普通神经网络层"><a href="#即普通神经网络层" class="headerlink" title="即普通神经网络层"></a>即普通神经网络层</h4><h4 id="相比于卷积层，参数数目较大"><a href="#相比于卷积层，参数数目较大" class="headerlink" title="相比于卷积层，参数数目较大"></a>相比于卷积层，参数数目较大</h4>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/06/cnn/" data-id="ck8p6nf0k000acwwi8vktcqso" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/07/06/conv-network/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          针对Cifar-10数据集建立的卷积神经网络
        
      </div>
    </a>
  
  
    <a href="/2019/07/05/SGD-Momentum/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">梯度下降问题处理以及算法优化</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/" rel="tag">TensorFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/deep-learning/" rel="tag">deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machine-learning/" rel="tag">machine learning</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/TensorFlow/" style="font-size: 10px;">TensorFlow</a> <a href="/tags/deep-learning/" style="font-size: 20px;">deep learning</a> <a href="/tags/machine-learning/" style="font-size: 15px;">machine learning</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/07/22/Cifar-batch-normalization/">批标准化+数据增强 处理后的Cifar-10 分类网络</a>
          </li>
        
          <li>
            <a href="/2019/07/22/Data-Enhancement/">TensorFlow数据增强API学习</a>
          </li>
        
          <li>
            <a href="/2019/07/13/activationfunction/">激活函数小结</a>
          </li>
        
          <li>
            <a href="/2019/07/12/inceptionnet/">InceptionNet</a>
          </li>
        
          <li>
            <a href="/2019/07/09/resnet/">残差网络(Residual Network)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>